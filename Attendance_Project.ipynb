{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "from PIL import ImageGrab\n",
    "import time\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import Message, Text\n",
    "import cv2\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tkinter.ttk as ttk\n",
    "import tkinter.font as font\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling():\n",
    "    path = 'ImagesAttendance'\n",
    "    images = []\n",
    "    classNames = []\n",
    "    myList = os.listdir(path)\n",
    "    #print(myList)\n",
    "    for cl in myList:\n",
    "        curImg = cv2.imread(f'{path}/{cl}')\n",
    "        images.append(curImg)\n",
    "        classNames.append(os.path.splitext(cl)[0])\n",
    "    #print(classNames)\n",
    "    return [images,classNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writecsv(name,starttime,endtime,t,p):\n",
    "    percent = (p/t)*100\n",
    "    if percent>=70:\n",
    "        s = \"Present\"\n",
    "    else:\n",
    "        s = \"Absent\"\n",
    "    with open(\"attend.csv\",\"a\") as f:\n",
    "        f.writelines(f'\\n{name},{starttime},{endtime},{percent},{s}\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def note(): \n",
    "    images,classNames = labeling()\n",
    "    encodeListKnown = findEncodings(images)\n",
    "    print('Encoding Complete')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    t=0\n",
    "    p=0\n",
    "    \n",
    "    #now = datetime.now()\n",
    "    t1 = time.localtime()\n",
    "    st = time.strftime(\"%H:%M:%S\",t1)\n",
    "    while True: \n",
    "        start=time.time()\n",
    "        f=0\n",
    "        success, img = cap.read()\n",
    "\n",
    "        imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "        imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        facesCurFrame = face_recognition.face_locations(imgS)\n",
    "        encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
    "\n",
    "        for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "\n",
    "            matchIndex = np.argmin(faceDis)\n",
    "\n",
    "            if matches[matchIndex]:\n",
    "                f=1\n",
    "                name = classNames[matchIndex].upper()\n",
    "\n",
    "                y1,x2,y2,x1 = faceLoc\n",
    "                y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
    "                cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "                cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "                #markAttendance(name)\n",
    "\n",
    "        cv2.imshow('Webcam',img)\n",
    "        key=cv2.waitKey(1)\n",
    "        if(key==ord(\"q\")):\n",
    "            break\n",
    "        iter_time = time.time()-start\n",
    "        t+=iter_time\n",
    "        if f==1:\n",
    "            p+=iter_time\n",
    "    t1 = time.localtime()\n",
    "    et = time.strftime(\"%H:%M:%S\",t1)\n",
    "    \n",
    "    writecsv(name,st,et,t,p)\n",
    "    \n",
    "    print(\"{:.2f} - {:.2f}\".format(t,p))\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\badri\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-7-c739740ced14>\", line 59, in <lambda>\n",
      "    command =lambda: Capture(txt2.get()), fg =\"white\", bg =\"blue\",\n",
      "  File \"<ipython-input-7-c739740ced14>\", line 44, in Capture\n",
      "    cv2.imshow(\"Press 'q' To Capture\", image)\n",
      "cv2.error: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-k1ohfcms\\opencv\\modules\\highgui\\src\\window.cpp:404: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Complete\n",
      "16.14 - 16.14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Face_Recogniser\")\n",
    "window.configure(background ='white')\n",
    "window.grid_rowconfigure(0, weight = 1)\n",
    "window.grid_columnconfigure(0, weight = 1)\n",
    "message = tk.Label(\n",
    "    window, text =\"Face-Recognition-System\",\n",
    "    bg =\"blue\", fg = \"white\", width = 50,\n",
    "    height = 3, font = ('times', 30, 'bold'))\n",
    "    \n",
    "message.place(x = 200, y = 20)\n",
    "\n",
    "lbl = tk.Label(window, text = \"No.\",\n",
    "width = 20, height = 2, fg =\"blue\",\n",
    "bg = \"white\", font = ('times', 15, ' bold ') )\n",
    "lbl.place(x = 400, y = 200)\n",
    "\n",
    "txt = tk.Entry(window,\n",
    "width = 20, bg =\"white\",\n",
    "fg =\"green\", font = ('times', 15, ' bold '))\n",
    "txt.place(x = 700, y = 215)\n",
    "\n",
    "lbl2 = tk.Label(window, text =\"Name\",\n",
    "width = 20, fg =\"blue\", bg =\"white\",\n",
    "height = 2, font =('times', 15, ' bold '))\n",
    "lbl2.place(x = 400, y = 300)\n",
    "\n",
    "txt2 = tk.Entry(window, width = 20,\n",
    "bg =\"white\", fg =\"green\",\n",
    "font = ('times', 15, ' bold ') )\n",
    "txt2.place(x = 700, y = 315)\n",
    "\n",
    "def Capture(name):\n",
    "    video=cv2.VideoCapture(0)\n",
    "    \n",
    "    os.makedirs(\".//ImagesAttendance\",exist_ok=True)\n",
    "    #name = input(\"Enter Your Name : \")\n",
    "    \n",
    "    a=1\n",
    "    while True:\n",
    "        a=a+1\n",
    "        check,image=video.read()\n",
    "\n",
    "        cv2.imshow(\"Press 'q' To Capture\", image)\n",
    "    \n",
    "        key=cv2.waitKey(1)\n",
    "        if(key==ord(\"q\")):\n",
    "            break\n",
    "    \n",
    "    cv2.imwrite(\"ImagesAttendance//\"+name+\".jpg\",image)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "takeImg = tk.Button(window, text =\"Capture\",\n",
    "command =lambda: Capture(txt2.get()), fg =\"white\", bg =\"blue\",\n",
    "width = 20, height = 3, activebackground = \"Red\",\n",
    "font =('times', 15, ' bold '))\n",
    "takeImg.place(x = 200, y = 500)\n",
    "\n",
    "# trainImg = tk.Button(window, text =\"Training\",\n",
    "# command = note, fg =\"white\", bg =\"green\",\n",
    "# width = 20, height = 3, activebackground = \"Red\",\n",
    "# font =('times', 15, ' bold '))\n",
    "# trainImg.place(x = 500, y = 500)\n",
    "\n",
    "trackImg = tk.Button(window, text =\"Start\",\n",
    "command = note, fg =\"white\", bg =\"blue\",\n",
    "width = 20, height = 3, activebackground = \"Red\",\n",
    "font =('times', 15, ' bold '))\n",
    "trackImg.place(x = 650, y = 500)\n",
    "\n",
    "quitWindow = tk.Button(window, text =\"End\",\n",
    "command = window.destroy, fg =\"white\", bg =\"blue\",\n",
    "width = 20, height = 3, activebackground = \"Red\",\n",
    "font =('times', 15, ' bold '))\n",
    "quitWindow.place(x = 1100, y = 500)\n",
    "\n",
    "\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Libraries\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "\n",
    "# Create an instance of TKinter Window or frame\n",
    "win = Tk()\n",
    "\n",
    "# Set the size of the window\n",
    "win.geometry(\"700x350\")\n",
    "\n",
    "# Create a Label to capture the Video frames\n",
    "label =Label(win)\n",
    "label.grid(row=0, column=0)\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "# Define function to show frame\n",
    "def show_frames():\n",
    "   # Get the latest frame and convert into Image\n",
    "   cv2image= cv2.cvtColor(cap.read()[1],cv2.COLOR_BGR2RGB)\n",
    "   img = Image.fromarray(cv2image)\n",
    "   # Convert image to PhotoImage\n",
    "   imgtk = ImageTk.PhotoImage(image = img)\n",
    "   label.imgtk = imgtk\n",
    "   label.configure(image=imgtk)\n",
    "   # Repeat after an interval to capture continiously\n",
    "   label.after(20, show_frames)\n",
    "\n",
    "show_frames()\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
